# ftune Cloud GPU Pricing Database
# Prices are per-GPU per-hour in USD.
# Sources: Official provider pricing pages.
# Last updated: 2025-02-10
#
# NOTE: Prices change frequently. Run `ftune pricing update` (future feature)
# or submit a PR to keep this current.

last_updated: "2025-02-10"

providers:
  lambda_labs:
    display_name: Lambda Labs
    website: https://lambdalabs.com/service/gpu-cloud
    gpus:
      H100-80GB:
        hourly_rate: 2.49
        instance_type: gpu_1x_h100_pcie
        gpu_count: 1
        region: us-east-1
      A100-80GB:
        hourly_rate: 1.99
        instance_type: gpu_1x_a100_sxm4
        gpu_count: 1
        region: us-east-1
      A100-40GB:
        hourly_rate: 1.29
        instance_type: gpu_1x_a100
        gpu_count: 1
        region: us-east-1
      RTX-4090-24GB:
        hourly_rate: 0.74
        instance_type: gpu_1x_rtx4090
        gpu_count: 1
        region: us-east-1

  runpod:
    display_name: RunPod
    website: https://www.runpod.io/pricing
    gpus:
      H100-80GB:
        hourly_rate: 3.29
        spot_hourly_rate: 2.39
        gpu_count: 1
      A100-80GB:
        hourly_rate: 1.64
        spot_hourly_rate: 1.34
        gpu_count: 1
      A100-40GB:
        hourly_rate: 1.24
        spot_hourly_rate: 0.84
        gpu_count: 1
      RTX-4090-24GB:
        hourly_rate: 0.69
        spot_hourly_rate: 0.39
        gpu_count: 1
      RTX-3090-24GB:
        hourly_rate: 0.44
        spot_hourly_rate: 0.29
        gpu_count: 1
      L4-24GB:
        hourly_rate: 0.44
        spot_hourly_rate: 0.29
        gpu_count: 1

  vast_ai:
    display_name: Vast.ai
    website: https://vast.ai/pricing
    gpus:
      H100-80GB:
        hourly_rate: 2.85
        gpu_count: 1
        note: "Marketplace pricing varies; this is median"
      A100-80GB:
        hourly_rate: 1.45
        gpu_count: 1
      A100-40GB:
        hourly_rate: 0.90
        gpu_count: 1
      RTX-4090-24GB:
        hourly_rate: 0.40
        gpu_count: 1
      RTX-3090-24GB:
        hourly_rate: 0.25
        gpu_count: 1

  together_ai:
    display_name: Together AI
    website: https://www.together.ai/pricing
    gpus:
      H100-80GB:
        hourly_rate: 2.50
        gpu_count: 1
      A100-80GB:
        hourly_rate: 1.25
        gpu_count: 1

  modal:
    display_name: Modal
    website: https://modal.com/pricing
    gpus:
      H100-80GB:
        hourly_rate: 3.95
        gpu_count: 1
      A100-80GB:
        hourly_rate: 3.00
        gpu_count: 1
      A100-40GB:
        hourly_rate: 1.78
        gpu_count: 1
      L4-24GB:
        hourly_rate: 0.59
        gpu_count: 1
      T4-16GB:
        hourly_rate: 0.27
        gpu_count: 1

  aws:
    display_name: AWS
    website: https://aws.amazon.com/ec2/pricing/on-demand/
    gpus:
      H100-80GB:
        hourly_rate: 12.36
        spot_hourly_rate: 4.95
        instance_type: p5.xlarge
        gpu_count: 1
        region: us-east-1
        note: "p5.48xlarge is $98.32/hr for 8 GPUs"
      A100-80GB:
        hourly_rate: 4.10
        spot_hourly_rate: 1.64
        instance_type: p4d.24xlarge
        gpu_count: 8
        region: us-east-1
        note: "Price shown is per-GPU; instance is 8x A100"
      T4-16GB:
        hourly_rate: 0.526
        spot_hourly_rate: 0.16
        instance_type: g4dn.xlarge
        gpu_count: 1
        region: us-east-1
      L4-24GB:
        hourly_rate: 0.81
        spot_hourly_rate: 0.24
        instance_type: g6.xlarge
        gpu_count: 1
        region: us-east-1

  gcp:
    display_name: Google Cloud
    website: https://cloud.google.com/gpu/pricing
    gpus:
      H100-80GB:
        hourly_rate: 11.86
        spot_hourly_rate: 3.56
        instance_type: a3-highgpu-1g
        gpu_count: 1
        region: us-central1
      A100-80GB:
        hourly_rate: 3.67
        spot_hourly_rate: 1.10
        instance_type: a2-highgpu-1g
        gpu_count: 1
        region: us-central1
      A100-40GB:
        hourly_rate: 2.95
        spot_hourly_rate: 0.89
        instance_type: a2-highgpu-1g
        gpu_count: 1
        region: us-central1
      T4-16GB:
        hourly_rate: 0.35
        spot_hourly_rate: 0.11
        instance_type: n1-standard-4 + T4
        gpu_count: 1
        region: us-central1
      L4-24GB:
        hourly_rate: 0.70
        spot_hourly_rate: 0.21
        instance_type: g2-standard-4
        gpu_count: 1
        region: us-central1
      V100-16GB:
        hourly_rate: 2.48
        spot_hourly_rate: 0.74
        instance_type: n1-standard-8 + V100
        gpu_count: 1
        region: us-central1

  azure:
    display_name: Microsoft Azure
    website: https://azure.microsoft.com/en-us/pricing/details/virtual-machines/linux/
    gpus:
      H100-80GB:
        hourly_rate: 11.56
        spot_hourly_rate: 3.47
        instance_type: ND_H100_v5
        gpu_count: 1
        region: eastus
      A100-80GB:
        hourly_rate: 3.67
        spot_hourly_rate: 1.10
        instance_type: ND96asr_A100_v4
        gpu_count: 1
        region: eastus
      T4-16GB:
        hourly_rate: 0.53
        spot_hourly_rate: 0.16
        instance_type: NC4as_T4_v3
        gpu_count: 1
        region: eastus
      V100-16GB:
        hourly_rate: 3.06
        spot_hourly_rate: 0.92
        instance_type: NC6s_v3
        gpu_count: 1
        region: eastus
