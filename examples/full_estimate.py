"""Full estimation example: memory + time + cost.

Run: python examples/full_estimate.py
"""

from ftune import Estimator


def main():
    print("=" * 65)
    print("  âš¡ ftune â€” Full Estimation: Memory + Time + Cost")
    print("=" * 65)

    est = Estimator(
        model="meta-llama/Llama-3.1-8B",
        method="qlora",
        quantization="4bit",
        lora_rank=16,
        batch_size=4,
        seq_length=2048,
    )

    # â”€â”€ Memory â”€â”€
    mem = est.estimate_memory()
    print(f"\nğŸ“¦ Model: {est.model_spec.name}")
    print(f"âš™ï¸  Method: QLoRA (rank=16, 4-bit)\n")
    print("â”Œâ”€â”€â”€ Memory Breakdown â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print(f"â”‚ Model weights:    {mem.model_weights_gb:>8.2f} GB              â”‚")
    print(f"â”‚ LoRA adapters:    {mem.trainable_params_gb:>8.2f} GB              â”‚")
    print(f"â”‚ Gradients:        {mem.gradients_gb:>8.2f} GB              â”‚")
    print(f"â”‚ Optimizer states: {mem.optimizer_states_gb:>8.2f} GB              â”‚")
    print(f"â”‚ Activations:      {mem.activations_gb:>8.2f} GB              â”‚")
    print(f"â”‚ CUDA overhead:    {mem.overhead_gb:>8.2f} GB              â”‚")
    print(f"â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚")
    print(f"â”‚ TOTAL:            {mem.total_gb:>8.2f} GB              â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    # â”€â”€ GPU Compatibility â”€â”€
    fits = est.check_gpu_fit()
    compatible = [g for g in fits if g.fits]
    incompatible = [g for g in fits if not g.fits]
    print(f"\nâœ… Fits on: {', '.join(g.gpu_name for g in compatible)}")
    if incompatible:
        print(f"âŒ Too large for: {', '.join(g.gpu_name for g in incompatible)}")

    # â”€â”€ Training Time â”€â”€
    dataset_size = 50000
    epochs = 3
    print(f"\nâ±ï¸  Training Time (dataset={dataset_size:,}, epochs={epochs}):\n")
    print(f"{'GPU':<18} {'Time/Epoch':>12} {'Total':>12}")
    print("â”€" * 44)

    times = est.estimate_time_all_gpus(dataset_size=dataset_size, epochs=epochs)
    for t in times[:6]:  # Show top 6
        print(f"{t.gpu_name:<18} {t.hours_per_epoch:>10.1f}h {t.total_hours:>10.1f}h")

    # â”€â”€ Cost Comparison â”€â”€
    print(f"\nğŸ’° Cost Comparison (using A100-80GB, {times[0].total_hours if times else '?'}h):\n")

    best_gpu = times[0].gpu_name if times else "A100-80GB"
    costs = est.estimate_costs(
        gpu="A100-80GB",
        dataset_size=dataset_size,
        epochs=epochs,
    )

    print(f"{'Provider':<18} {'$/hr':>8} {'Total':>10} {'Spot':>10}")
    print("â”€" * 48)
    for c in costs.estimates:
        spot = f"${c.spot_total_cost:.2f}" if c.spot_total_cost else "â€”"
        print(f"{c.provider:<18} ${c.hourly_rate:>6.2f} ${c.total_cost:>8.2f} {spot:>10}")

    if costs.cheapest:
        print(f"\nğŸ’¡ Cheapest on-demand: {costs.cheapest}")
    if costs.best_value:
        print(f"ğŸ† Best value: {costs.best_value}")

    # â”€â”€ Full comparison â”€â”€
    print("\n" + "=" * 65)
    print("  ğŸ” Full Comparison (all GPUs Ã— all providers)")
    print("=" * 65 + "\n")

    full = est.full_comparison(dataset_size=dataset_size, epochs=epochs)
    print(f"{'Provider':<18} {'GPU':<16} {'Hours':>6} {'$/hr':>8} {'Total':>10}")
    print("â”€" * 60)
    for c in full.estimates[:15]:  # Top 15 cheapest
        print(
            f"{c.provider:<18} {c.gpu:<16} {c.training_hours:>5.1f}h "
            f"${c.hourly_rate:>6.2f} ${c.total_cost:>8.2f}"
        )

    print(f"\nğŸ† Cheapest option: {full.cheapest}")
    print(f"ğŸ’¡ Best value: {full.best_value}")


if __name__ == "__main__":
    main()
